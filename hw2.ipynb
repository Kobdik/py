{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17313cd2-8562-4451-87f9-7574d851baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b1aa3d-23d8-4f97-8311-fa21a2cd7b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=256\n",
    "\n",
    "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
    "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=tv.transforms.ToTensor(), download=True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a360d994-4dd8-45ad-8933-c646a8335e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 9\n"
     ]
    }
   ],
   "source": [
    "# shape of first train example (normalized) and first label\n",
    "print(train_dataset[0][0].shape, train_dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "988af803-343b-4271-807e-507fd23f0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 2048),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(2048),\n",
    "    # torch.nn.Dropout(.5),\n",
    "    torch.nn.Linear(2048, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    # torch.nn.Dropout(.5),\n",
    "    torch.nn.Linear(512, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(64),\n",
    "    # torch.nn.Dropout(.5),\n",
    "    torch.nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df91d19e-d871-4ed5-ae18-8556313be431",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "num_epochs = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e637fc5-772f-4eb3-bf63-5169607fd7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for ep in range(num_epochs):\n",
    "        #  train phase\n",
    "        train_iters, train_passed = 0, 0\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        start = time.time()\n",
    "        model.train()\n",
    "        for X, y in train:\n",
    "            trainer.zero_grad()\n",
    "            # make calculation tree\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            # compute gradients of model parameters\n",
    "            loss.backward()\n",
    "            # updates the parameters after gradients are computed\n",
    "            trainer.step()\n",
    "            # accumulate resuts\n",
    "            train_loss += loss.item()\n",
    "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "        #  test phase\n",
    "        test_iters, test_passed  = 0, 0\n",
    "        test_loss, test_acc = 0., 0.\n",
    "        model.eval()\n",
    "        for X, y in test:\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            test_iters += 1\n",
    "            test_passed += len(X)\n",
    "        \n",
    "        print(\"ep: {}, time: {:.3f}, trn_l: {:.6f}, trn_a: {:.6f}, tst_l: {:.6f}, tst_a: {:.6f}\".format(\n",
    "            ep, time.time() - start, \n",
    "            train_loss / train_iters, train_acc / train_passed, \n",
    "            test_loss / test_iters, test_acc / test_passed)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b8ea486-c486-42e4-87a3-b51bf146bebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, time: 11.173, trn_l: 0.190114, trn_a: 0.929067, tst_l: 0.767738, tst_a: 0.876900\n",
      "ep: 1, time: 11.539, trn_l: 0.147753, trn_a: 0.943783, tst_l: 2.067132, tst_a: 0.878000\n",
      "ep: 2, time: 11.759, trn_l: 0.132908, trn_a: 0.948833, tst_l: 2.032338, tst_a: 0.869800\n",
      "ep: 3, time: 11.872, trn_l: 0.127515, trn_a: 0.951417, tst_l: 0.690243, tst_a: 0.865900\n",
      "ep: 4, time: 11.996, trn_l: 0.129903, trn_a: 0.950250, tst_l: 2.299798, tst_a: 0.876700\n",
      "ep: 5, time: 12.094, trn_l: 0.116718, trn_a: 0.955367, tst_l: 2.978481, tst_a: 0.880400\n",
      "ep: 6, time: 12.168, trn_l: 0.111579, trn_a: 0.957567, tst_l: 6.962951, tst_a: 0.871000\n",
      "ep: 7, time: 12.144, trn_l: 0.105514, trn_a: 0.959367, tst_l: 5.718908, tst_a: 0.876400\n",
      "ep: 8, time: 12.124, trn_l: 0.106049, trn_a: 0.958883, tst_l: 5.078902, tst_a: 0.881300\n",
      "ep: 9, time: 11.986, trn_l: 0.106538, trn_a: 0.959683, tst_l: 3.161078, tst_a: 0.875000\n",
      "ep: 10, time: 12.195, trn_l: 0.100460, trn_a: 0.960683, tst_l: 2.634406, tst_a: 0.885400\n",
      "ep: 11, time: 12.401, trn_l: 0.088097, trn_a: 0.965483, tst_l: 5.402330, tst_a: 0.878200\n",
      "ep: 12, time: 12.149, trn_l: 0.090480, trn_a: 0.966167, tst_l: 5.748490, tst_a: 0.875000\n",
      "ep: 13, time: 12.083, trn_l: 0.087037, trn_a: 0.967033, tst_l: 5.286566, tst_a: 0.877000\n",
      "ep: 14, time: 12.210, trn_l: 0.079818, trn_a: 0.969717, tst_l: 24.052693, tst_a: 0.880600\n",
      "ep: 15, time: 12.468, trn_l: 0.084855, trn_a: 0.967667, tst_l: 12.433674, tst_a: 0.875100\n",
      "ep: 16, time: 12.222, trn_l: 0.071036, trn_a: 0.973233, tst_l: 7.320058, tst_a: 0.880600\n",
      "ep: 17, time: 12.204, trn_l: 0.073771, trn_a: 0.971900, tst_l: 19.945668, tst_a: 0.874800\n",
      "ep: 18, time: 12.484, trn_l: 0.074702, trn_a: 0.971850, tst_l: 4.902309, tst_a: 0.878000\n",
      "ep: 19, time: 12.302, trn_l: 0.066281, trn_a: 0.975433, tst_l: 5.311954, tst_a: 0.882600\n",
      "ep: 20, time: 12.256, trn_l: 0.062973, trn_a: 0.976667, tst_l: 10.589922, tst_a: 0.883300\n",
      "ep: 21, time: 12.364, trn_l: 0.104957, trn_a: 0.961417, tst_l: 14.465537, tst_a: 0.865800\n",
      "ep: 22, time: 12.210, trn_l: 0.104026, trn_a: 0.961017, tst_l: 10.050586, tst_a: 0.882300\n",
      "ep: 23, time: 12.138, trn_l: 0.055701, trn_a: 0.978550, tst_l: 14.402331, tst_a: 0.883600\n",
      "ep: 24, time: 12.366, trn_l: 0.049859, trn_a: 0.981150, tst_l: 15.729432, tst_a: 0.875700\n",
      "ep: 25, time: 12.309, trn_l: 0.051712, trn_a: 0.980050, tst_l: 20.641773, tst_a: 0.878500\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7f878-a19f-484f-824e-424121f7a37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy greater than 0.88 at epoch: 5, 8, 10, 14, 16, 19, 20, 22, 23 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
